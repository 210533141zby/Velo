# 性能故障排除报告

## 问题 1: 资源库加载延迟 (Redis 超时)
**日期:** 2025-12-29
**状态:** 已解决

### 问题描述
用户报告在加载 Wiki 应用程序的“资源库”页面时存在显著延迟（约 2-3 分钟）。环境是 Windows，但需求是支持 Linux/企业标准（Redis）。

### 根本原因分析 (Root Cause Analysis)
1.  **Redis 连接超时**: 应用程序配置为连接 Redis 服务器（Linux 部署的标准配置）。
2.  **环境不匹配**: 在 Windows 本地环境中，Redis 并未运行。
3.  **阻塞式 IO**: 默认的 `redis-py` 连接逻辑（或 `aioredis`）具有非常长的默认超时时间（socket 超时）。当应用程序尝试连接不存在的 Redis 服务器时，它会一直挂起，直到操作系统/TCP 栈超时（约 2 分钟）。
4.  **缺乏降级机制**: 原始代码没有在 Redis 失败时优雅地降级到内存缓存的机制。

### 解决方案实施: 企业级混合缓存
为了同时满足“企业标准”（使用 Redis）和“本地/Windows 兼容性”（速度），我们实现了 **混合缓存管理器 (Hybrid Cache Manager)**。

#### 关键特性
1.  **快速故障检测**:
    - 配置 `socket_connect_timeout=1` 和 `socket_timeout=1`（1 秒）。
    - 这确保了如果 Redis 宕机，应用程序能立即检测到，而不是挂起。

2.  **自动降级**:
    - 如果在启动或运行时 Redis 连接失败，系统会自动切换到 `_memory_cache`（Python 字典）。
    - 这为本地开发提供了 0ms 的延迟，同时保持了生产就绪状态。

3.  **日志记录**:
    - 详细的日志会写入 `user_ops.log` 和标准输出，指示当前激活的是“Redis 模式”还是“降级模式”。

### 验证
- **场景 A (Redis 宕机)**: 应用启动 -> 尝试 Redis (1s) -> 失败 -> 切换到内存 -> 应用瞬间工作。
- **场景 B (Redis 正常)**: 应用启动 -> 连接 Redis -> 使用 Redis 进行分布式缓存 -> 应用瞬间工作。

### 代码参考
- **缓存逻辑**: [cache.py](file:///d:\Working\seek\Wiki\backend\app\core\cache.py)
- **端点**: [documents.py](file:///d:\Working\seek\Wiki\backend\app\api\endpoints\documents.py) (使用 `redis_manager`)

---

## 问题 2: 保存缓慢及 "Error saving" (ChromaDB 阻塞)
**日期:** 2025-12-29
**状态:** 已解决

### 问题描述
用户报告保存文档极其缓慢（停留在 "Saving..." 悬停状态），并经常失败显示 "Error saving" 消息。此外，日志不完整，显示请求开始但缺少失败请求的完成条目。

### 根本原因分析 (Root Cause Analysis)
1.  **重复的重型初始化**: `AgentService` 在 *每次* 请求时都初始化 `Chroma` 向量数据库实例。加载向量数据库（即使是基于 SQLite 的小型数据库）是一个 IO 密集型操作，增加了显著的开销。
2.  **事件循环阻塞**: ChromaDB 的操作（`add_documents`, `persist`）是同步的（阻塞的）。尽管它们被放置在 FastAPI 的 `BackgroundTasks` 中，但它们是在主线程中执行的。在 Python 的 `asyncio` 模型中，在主线程运行长时间的同步代码会阻塞整个事件循环，阻止服务器处理其他请求（包括前端的保持活跃或成功检查），导致超时。
3.  **数据库会话冲突**: 后台任务试图重用已关闭的数据库会话或不正确地创建会话，导致潜在的死锁或未被正确记录的错误。

### 解决方案实施: 异步优化与单例模式

#### 1. 向量存储的单例模式
我们为 ChromaDB 实例实现了一个全局单例，以确其在应用程序生命周期中仅初始化 **一次**，而不是每次请求都初始化。

```python
# app/services/agent_service.py
_vector_store_instance = None
def get_vector_store():
    # ... 检查实例是否存在，若不存在则创建 ...
    return _vector_store_instance
```

#### 2. 非阻塞线程池执行
我们使用 `fastapi.concurrency.run_in_threadpool` 将同步的 ChromaDB 操作卸载到单独的线程池。这允许主 `asyncio` 事件循环保持响应，而繁重的 IO 操作在后台进行。

```python
# app/services/agent_service.py
from fastapi.concurrency import run_in_threadpool

async def index_document(...):
    # 在线程池中运行同步方法
    await run_in_threadpool(self.vector_store.add_documents, docs)
```

#### 3. 增强的日志与监控
我们添加了中间件来记录每个请求的 **开始** 和 **结束**，包括执行时间和客户端 IP。这对于识别请求是“挂起”还是仅仅快速失败至关重要。

```python
# app/main.py
@app.middleware("http")
async def log_requests(request: Request, call_next):
    # 记录开始
    response = await call_next(request)
    # 记录结束 + 耗时
    # ...
```

### 经验教训 (Lessons Learned)
1.  **Async/Sync 边界**: 在像 FastAPI 这样的 `async` 框架中，永远不要直接在主路径中运行繁重的同步代码（如文件 IO 或繁重计算）。始终使用 `await run_in_threadpool()` 或 `asyncio.to_thread()`。
2.  **资源管理**: 繁重的资源如数据库连接或 ML 模型（向量数据库）应始终为单例或池化，永远不要按请求实例化。
3.  **可观测性**: 调试“挂起”问题时，标准日志通常会失败，因为它们只在完成 *后* 记录。记录操作的 *开始* 对于定位进程死锁或挂起的位置至关重要。

### 代码参考
- **服务逻辑**: [agent_service.py](file:///d:\Working\seek\Wiki\backend\app\services\agent_service.py)
- **中间件**: [main.py](file:///d:\Working\seek\Wiki\backend\app\main.py)
