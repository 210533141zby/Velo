version: '3.8'

services:
  backend:
    build: ./backend
    container_name: metis_backend
    restart: always
    ports:
      - "8000:8000"
    environment:
      - POSTGRES_SERVER=sqlite
      - VLLM_API_URL=http://vllm:8000/v1
      - REDIS_HOST=redis
    volumes:
      - ./backend:/app
      - backend_data:/app/data
    depends_on:
      - redis
      - vllm
    # 移除 host 模式，加入默认网络以便与 redis/frontend 通信
    # network_mode: "host" 
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # === Frontend Service ===
  frontend:
    # image: swze/metis-frontend:latest
    build: ./frontend
    container_name: metis_frontend
    restart: always
    ports:
      - "80:80"
    depends_on:
      - backend

  # === Redis Service ===
  redis:
    image: redis:7-alpine
    container_name: metis_redis
    restart: always
    volumes:
      - redis_data:/data

  # === vLLM Service (Large Language Model) ===
  # 官方高性能推理引擎，不需要自己构建镜像
  # === vLLM Service ===
  # === vLLM Service ===
  vllm:
    image: vllm/vllm-openai:v0.6.2
    container_name: metis_vllm
    restart: always
    ports:
      - "8001:8000"
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    # === 针对 3090 和方案优化后的启动参数 ===
    command: --model Qwen/Qwen2.5-Coder-14B-Instruct-AWQ --quantization awq --dtype half --gpu-memory-utilization 0.95 --max-model-len 32768 --enable-prefix-caching --trust-remote-code
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  redis_data:
  backend_data:
