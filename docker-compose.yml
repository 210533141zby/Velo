version: '3.8'

services:
  backend:
    build: ./backend
    container_name: metis_backend
    restart: always
    ports:
      - "8000:8000"
    environment:
      - POSTGRES_SERVER=sqlite
      - VLLM_API_URL=http://vllm:8000/v1
      - REDIS_HOST=redis
      - ANONYMIZED_TELEMETRY=False  # 禁用 ChromaDB 的遥测，防止 PostHog 连接报错
      
      - DATA_DIR=/app/data
    volumes:
      
      - ./backend:/app
    depends_on:
      - redis
      - vllm
   
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

 
  frontend:
    build: ./frontend
    container_name: metis_frontend
    restart: always
    ports:
      - "80:80"
    depends_on:
      - backend

 
  redis:
    image: redis:7-alpine
    container_name: metis_redis
    restart: always
    volumes:
      - redis_data:/data


  vllm:
    image: vllm/vllm-openai:v0.6.2
    container_name: metis_vllm
    restart: always
    ports:
      - "8001:8000"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
      - VLLM_NCCL_SO_PATH=/usr/lib/x86_64-linux-gnu/libnccl.so.2
    volumes:
      - ./models:/models
    command: >
      --model /models/Qwen/Qwen2___5-Coder-14B-Instruct-GPTQ-Int4
      --served-model-name Qwen/Qwen2.5-Coder-14B-Instruct-GPTQ-Int4
      --quantization gptq
      --dtype half
      --gpu-memory-utilization 0.9
      --max-model-len 8192
      --trust-remote-code
      --enforce-eager
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  redis_data: